{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Project 3: Training a BiLSTM POS tagger\n",
    "##Due: November 4, 2021 \n",
    "\n",
    "The goal of this project is to train a BILSTM model for sequence labeling. \n",
    "\n",
    "##Task definition:\n",
    "POS tagging is the task of assigning a POS tag to each word token in the sentence, and it is a typical sequence labeling problem. The provided code has a skeletal implementation of a CRF tagger, complete with a Viterbi decoder and a function for computing the negative loglikelihood of a sentence with the forward algorithm.\n",
    "\n",
    "You are asked to write a training routine to train a sequence labeling model with the provided training set from the Penn TreeBank. Make sure you include code in the training routine that reports the total loss after each training iteration (epoch) over the entire training set so that you can observe the change in the total loss from iteration to iteration. If the training goes well, the loss should keep going down. If you see drastic upward and downward swings in the training loss, that's a sign that something is not working properly. Additionally you should also include code that reports the accuracy of the model on the development set every 5 or 10 iterations, so that you can observe the trend in prediction accuracy. If the improvement plateaus or starts to go down, that's a sign you should stop training.\n",
    "\n",
    "Additionally, you are asked to write an alternative (and simpler) per-token local softmax decoder that finds the best tag for each word token individually. You also need to write a corresponding negative loglikelihood loss function for such a greedy decoding process. Recall that in this case the negative loglikelihood loss of a sentence is the sum of the loss for individual word tokens in the sentence. This will allow you to compare the performance of this simpler alternative with the CRF model. \n",
    "\n",
    "\n",
    "##Data sets:\n",
    "We will be using the standard train / development / test split in the Penn TreeBank for our experiments: Sections\n",
    "02-21 are used for training, Section 22 is used for devevelopment, and Section 23 is used as the final test set.\n",
    "You can use the development set to select the best model architecture and tune the hyperparameters. When you are done\n",
    "training and tuning, you need to run your code on the test set and produce an automatically tagged version of it.\n",
    "The data format is very straightforward: each line of the data file contains one sentence. For the training and dev data, you are provided with the sentences with their gold POS tags. For the test set, you are only given the word tokens. The TAs will run your code on the test set to get the accuracy of your model\n",
    "\n",
    "\n",
    "##Experiments\n",
    "Like linear models, having the right feature representation is crucial to the performance of a neural model. In neural models, you can no longer tweak the feature templates directly. However, you can engineer a neural architecture to capture information that is analoguous to features in linear models. For instance, the BiLSTM network captures the left and right context, similar to previous and next word features in linear models. To capture affix information that might be helpful for POS tagging, you can experiment with character-level CNNs with various pooling techniques (e.g., max pooling). To capture previous tag features, you can use a transition matrix between tags.\n",
    "You are asked to run a number of experiments and report results on the provided development set in this assignment.\n",
    "\n",
    "1. Experiment with using pre-trained word embeddings such as GLOVE (https://nlp.stanford.edu/projects/glove/) or fastText (https://fasttext.cc/docs/en/english-vectors.html). These embeddings come with different dimensions, and start with a smaller dimension to make sure that your computing environment has sufficient memory for it and your model can train sufficiently fast. You are adviced to \"freeze\" the word embeddings and do not update them during your training process. Compare the results from using the best pre-training embeddings and using random initialized embeddings to see if there is any difference in performance.\n",
    "\n",
    "2. Experiment with using character CNNs. Intuitively affixes or other parts of a word can be useful information. Typically this information is captured with character-level CNNs in neural models. Add a character-level CNN, and concatenate the output of the CNN with word embeddings, and see if this improves the performance of your BiLSTM model. Compare the results of using vs not using character CNNs.\n",
    "\n",
    "3. Do the first two experiments with a local softmax decoder, i.e., making predictions individually for each word in the sentence, as this will train faster. You should be able to train your model with (the sum of) a per-token negative loglikelihood loss on the entire training set within a reasonable amoount of time. In the final experiment, you are asked to compare the results for the greedy per-token local loss with the global negative loglikelihood loss on the entire tag sequence with a BiLSTM-CRF model. Training a BiLSTM-CRF model is expensive, so use the first 10,000 sentences to train the CRF model instead of the entire training set. For apple-to-apple comparisions, also train your local greedy softmax model with the same training set so that you can observe which model yields superior performance.\n",
    "\n",
    "##Some implementation tips:\n",
    "\n",
    "1. To take advantage of the GPU accelerator, you need to move all Pytorch tensors to GPU using to(device) or cuda().\n",
    "2. A common first problem is that you'll use up all memory quickly, leading to an \"out of memory\" error. It is important to realize that Pytorch keep a computation history to compute the gradient. For instance, if you add up the losses for individual sentences, you may keep accumulating history and use up the memory. So instead of doing something like 'total_loss += sent_loss\", do \"total_loss += float(sent_loss)\" to strip off history.  Also delete variables you no longer need to free up memory.\n",
    "4. Dealing with unknown words: add UNK to the training vocabulary so that if there is an out-of-vocabulary (OOV) word in the development set, you can map it to UNK so that it still gets labeled.\n",
    "5. If the loss (negative loglikelihood) swings up and down, you may need to adjust the learning rate (or choose a different optimizer). We suggest that you use the Adam optimizer as it is adaptive and you don't need to manually set the learning rate. \n",
    "6. In a typical deep learning model, there are many hyper-parameters that need to be manually set (learning rate /choice of optimizer, embedding and hidden dimensions, kernel sizes (CNN), number of training iterations, etc., ). This leads to many different combinations of hyper-parameters and it is hard to do an exhaustive search to find the best combination. One common technique for searching the best set of parameters is *grid search*, which allows you to specify plausible values for each hyper-paraameter and search for hyper-parameter combinations systematically.\n",
    "\n",
    "##Report\n",
    "Write a report that a) briefly describe the structure of your code, b) present your experimental settings and\n",
    "results, and c) any insights that you have learned from your experiments. Your report should be no longer than 5\n",
    "pages.\n",
    "\n",
    "##Project evaluation criteria\n",
    "\n",
    "Your project will be evaluated by the correctness and thoroughness of your implementation (performing all required experiments), the performance of your best model, which usually reflects the correctness and thoroughness of your model as well as the proper selection of hyper-parameters. Your project will also be evaluated against creativity (e.g., surprising model components that lead to consistent improvement in performance), and clarity of your report. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 0.002\n",
    "EMBED_DIM = 50\n",
    "HIDDEN_DIM = 50\n",
    "NUM_LAYERS = 1\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.2\n",
    "SEED = 1334\n",
    "DEVICE_ID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{DEVICE_ID}\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_gold_data(filename):\n",
    "    \"\"\"Read in the labeled gold data into a list\"\"\"\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            tuples = [tup.split('_') for tup in line.split()]\n",
    "            tokens = [tup[0] for tup in tuples]\n",
    "            tags = [tup[1] for tup in tuples]\n",
    "            yield (tokens, tags)\n",
    "\n",
    "def batchify(dataset, batch_size=50):\n",
    "    \"\"\"Divide the training set into batches for mini-batch training\"\"\"\n",
    "    dataset = list(dataset)\n",
    "    sent_count = len(dataset)\n",
    "    start = 0\n",
    "    for batch in range(int(sent_count / batch_size)):\n",
    "        start = batch * batch_size\n",
    "        yield dataset[start : start + batch_size]\n",
    "    if sent_count % batch_size != 0:\n",
    "        yield dataset[start+batch_size:]\n",
    "        \n",
    "\n",
    "def read_in_plain_data(filename):\n",
    "    \"\"\"Read in plain text data for sequence labeling, assuming a one-sentence-per-line format\"\"\"\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.split() for line in lines]\n",
    "    return lines\n",
    "\n",
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "def prepare_sequence(seq, to_ix, to_chidx):\n",
    "    UNK = '<UNK>'\n",
    "    idxs = [to_ix[w] if w in to_ix else to_ix[UNK] for w in seq]\n",
    "    chseqs = [[c.lower() for c in token] for token in seq]\n",
    "    ch_padded = pad_seq(chseqs, to_chidx)\n",
    "    return torch.tensor(idxs, dtype=torch.long), torch.tensor(ch_padded,dtype=torch.long)\n",
    "\n",
    "\n",
    "def pad_seq(seqs, to_charidx):\n",
    "    PAD  = '<PAD>'\n",
    "    maxlen = max([len(seq) for seq in seqs])\n",
    "    if maxlen < 3: maxlen = 3\n",
    "    for seq in seqs:\n",
    "        seq += [\"<PAD>\"] * (maxlen - len(seq))\n",
    "    padded = [[to_charidx[ch] for ch in seq] for seq in seqs]\n",
    "    return padded\n",
    "            \n",
    "\n",
    "def id_to_str(tagidseq, to_str):\n",
    "    return [to_str[tagid] for tagid in tagidseq]\n",
    "\n",
    "\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
    "\n",
    "##Code for evaluating the performance of the tagger on a test/development set\n",
    "def compare_tagseq(goldseq, predicted_seq):\n",
    "    \"\"\"Compare two sequences and output the length of the sequence \n",
    "    and the number of tags they share. A helper function to the evaluation function\"\"\"\n",
    "    pairs = zip(goldseq, predicted_seq)\n",
    "    correct = len([1 for pair in pairs if pair[0]== pair[1]])\n",
    "    return len(goldseq), correct\n",
    "\n",
    "def eval_model(devset, word_to_ix, ix_to_tag, char_to_ix, model):\n",
    "    \"\"\"Given a development set and a model, compute the accuracy of the model prediction\n",
    "    on the development set\"\"\"\n",
    "    total_tokens = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for sent, tags in devset:\n",
    "            word_tensor, char_tensor = prepare_sequence(sent, word_to_ix, char_to_ix)\n",
    "            sentence_in = (word_tensor.to(device), char_tensor.to(device))\n",
    "            scores, tagidseq = model(sentence_in)\n",
    "            predicted_tags = id_to_str(tagidseq, ix_to_tag)\n",
    "            sent_length, length_correct = compare_tagseq(tags,predicted_tags)\n",
    "            correct += length_correct\n",
    "            total_tokens += sent_length\n",
    "    return correct/total_tokens\n",
    "\n",
    "## Code the read in pre-trained word embeddings\n",
    "def glove2dict(glove_path,emb_dim=50):\n",
    "    \"\"\"Read in glove embeddings and create a dictionary\"\"\"\n",
    "    glove_dict = {}\n",
    "    if emb_dim == 50:\n",
    "        fname= \"glove.6B.50d.txt\"\n",
    "    elif emb_dim == 100:\n",
    "        fname=\"glove.6B.100d.txt\"\n",
    "    elif emb_dim == 200:\n",
    "        fname=\"glove.6B.200d.txt\"\n",
    "    elif emb_dim == 300:\n",
    "        fname=\"glove.6B.300d.txt\"\n",
    "    else:\n",
    "        print(\"Inappropriate glove size chosen, using 50\")\n",
    "        fname=\"glove.6B.50d.txt\"\n",
    "    with open(f'{glove_path}/{fname}', 'rb') as f:\n",
    "        for l in f:\n",
    "            line = l.decode().split()\n",
    "            word = line[0]\n",
    "            vect = np.array(line[1:]).astype(np.float)\n",
    "            glove_dict[word]=vect\n",
    "    return glove_dict\n",
    "\n",
    "def create_glove_embeddings(glove_path, target_vocab_index, emb_dim=50):\n",
    "    \"\"\"create the glove embeddings for a target dictionary\"\"\"\n",
    "    glove_dict = glove2dict(glove_path, emb_dim)\n",
    "    matrix_len = len(target_vocab_index) \n",
    "  \n",
    "    weight_matrix = np.zeros((matrix_len, emb_dim))\n",
    "    words_found = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artificial sentence\n",
    "test_data = \"Alphabet_NN Inc._NN showed_VB new_JJ TV_NN ads_NN yesterday_NN ._.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_itos, tgt_itos = set(), set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in training_data:\n",
    "    sent = [x.split('_') for x in sent.split()]\n",
    "    sent_src, sent_tgt = zip(*sent)\n",
    "    src_itos.update(sent_src)\n",
    "    tgt_itos.update(sent_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_itos, tgt_itos = sorted(src_itos), sorted(tgt_itos)\n",
    "tgt_itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK = '<unk>'\n",
    "BOS = '<bos>' # CRF\n",
    "EOS = '<eos>' # CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_itos = [UNK] + src_itos\n",
    "src_stoi = {word: i for i, word in enumerate(src_itos)}\n",
    "src_vocab = (src_itos, src_stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_itos = [BOS, EOS] + tgt_itos\n",
    "tgt_stoi = {word: i for i, word in enumerate(tgt_itos)}\n",
    "tgt_vocab = (tgt_itos, tgt_stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vectorized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_seq(seq, vocab, is_target=False):\n",
    "    if type(seq) is str:\n",
    "        seq = seq.split()\n",
    "\n",
    "    out_seq = []\n",
    "    for tok in seq:\n",
    "        if tok in vocab:\n",
    "            out_seq.append(vocab[tok])\n",
    "        else:\n",
    "            if is_target:\n",
    "                raise RuntimeError(f\"Unknown target token: `{repr(tok)}` from vocab: {', '.join(vocab)}\")\n",
    "            else:\n",
    "                out_seq.append(vocab[UNK])\n",
    "\n",
    "    return out_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_vectors = []\n",
    "for sent in training_data:\n",
    "    sent = [x.split('_') for x in sent.split()]\n",
    "    src, tgt = zip(*sent)\n",
    "    src = torch.tensor([convert_seq(src, src_stoi)], dtype=torch.long)\n",
    "    tgt = torch.tensor(convert_seq(tgt, tgt_stoi, is_target=True), dtype=torch.long)\n",
    "    training_vectors.append((src, tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector = [x.split('_') for x in test_data.split()]\n",
    "test_src, test_tgt = zip(*test_vector)\n",
    "test_vector = [\n",
    "    torch.tensor([convert_seq(test_src, src_stoi)], dtype=torch.long),\n",
    "    torch.tensor(convert_seq(test_tgt, tgt_stoi, is_target=True), dtype=torch.long)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BiLSTM-CRF POS Tagger Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(src_itos)\n",
    "output_dim = len(tgt_itos)\n",
    "input_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, device):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, EMBED_DIM)\n",
    "        self.lstm = nn.LSTM(EMBED_DIM, HIDDEN_DIM, num_layers=NUM_LAYERS, batch_first=True, bidirectional=BIDIRECTIONAL)\n",
    "        self.linear = nn.Linear(HIDDEN_DIM*2 if BIDIRECTIONAL else HIDDEN_DIM, output_dim) # project to vocab space\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "        self.device = device\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        direction_multiplier = 2 if BIDIRECTIONAL else 1\n",
    "        return (torch.randn(direction_multiplier * NUM_LAYERS, 1, HIDDEN_DIM, device=self.device), # h0\n",
    "                torch.randn(direction_multiplier * NUM_LAYERS, 1, HIDDEN_DIM, device=self.device)) # c0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embed = self.embedding(x)\n",
    "        embed = self.dropout(embed)\n",
    "        outputs, _ = self.lstm(embed, self.hidden)\n",
    "        outputs = self.linear(outputs)\n",
    "        return outputs.squeeze() # assumes batch size of 1, whose dimension will be reduced here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRF(nn.Module):\n",
    "    \"\"\"TODO: Impelement CRF forward, score and viterbi functions\"\"\"\n",
    "    def __init__(self, tgt_vocab, device):\n",
    "        super().__init__()\n",
    "        self.tgt_itos, self.tgt_stoi = tgt_vocab\n",
    "        self.tag_size = len(self.tgt_itos)\n",
    "        self.device = device\n",
    "        \n",
    "        # transition matrix\n",
    "        self.transitions = nn.Parameter(torch.randn(self.tag_size, self.tag_size, device=self.device))\n",
    "        self.transitions.data[self.tgt_stoi[BOS], :] = -1000.\n",
    "        self.transitions.data[:, self.tgt_stoi[EOS]] = -1000.\n",
    "    \n",
    "    def forward(self, feats):\n",
    "        raise NotImplementedError(\"Implement this\")\n",
    "    \n",
    "    def score(self, feats, tags):\n",
    "        raise NotImplementedError(\"Implement this\")\n",
    "    \n",
    "    def viterbi(self, feats):\n",
    "        raise NotImplementedError(\"Implement this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  BiLSTM_CRF(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, tgt_vocab, device):\n",
    "        super().__init__()\n",
    "        self.lstm = BiLSTM(input_dim, output_dim, device=device)\n",
    "        self.crf = CRF(tgt_vocab, device=device)\n",
    "    \n",
    "    def neg_log_likelihood(self, src, tgt):\n",
    "        \"\"\"Compute negative log likelihood given sentence and gold POS labels\"\"\"\n",
    "        feats = self.lstm(src)\n",
    "        forward_score = self.crf(feats)\n",
    "        gold_score = self.crf.score(feats, tgt)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"Tag a single sentence\"\"\"\n",
    "        feats = self.lstm(src)\n",
    "        out = self.crf.viterbi(feats)\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  BiLSTM_greedy(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, tgt_vocab, device):\n",
    "        super().__init__()\n",
    "        self.lstm = BiLSTM(input_dim, output_dim, device)\n",
    "\n",
    "    \n",
    "    def neg_log_likelihood(self, src, tgt):\n",
    "        \"\"\"Compute negative log likelihood given sentence and gold POS labels\"\"\"\n",
    "        raise NotImplementedError(\"Implement this\")\n",
    "        \n",
    "\n",
    "    def forward(self, src):\n",
    "        \"\"\"Tag a single sentence\"\"\"\n",
    "        raise NotImplementedError(\"Implement this\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM_CRF(input_dim, output_dim, tgt_vocab, device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_src, test_tgt = test_vector\n",
    "\" \".join(src_itos[x] for x in test_src.squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(tgt_itos[x] for x in test_tgt.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, pred_seq = model(test_src.to(device))\n",
    "score.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold\n",
    "\" \".join(tgt_itos[x] for x in test_tgt.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred\n",
    "\" \".join(tgt_itos[x] for x in torch.cat(pred_seq, 0).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_EPOCHS):\n",
    "    epoch_loss = 0.\n",
    "    num_correct = 0\n",
    "    num_tokens = 0\n",
    "    \n",
    "    model.train()\n",
    "    for src, tgt in tqdm.tqdm(training_vectors, desc=f\"[Training {i+1}/{NUM_EPOCHS}]\"):\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        loss = model.neg_log_likelihood(src, tgt)\n",
    "        epoch_loss += loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, pred = model(src)\n",
    "        num_correct += (torch.cat(pred, 0)==tgt).sum()\n",
    "        num_tokens += len(tgt)\n",
    "        \n",
    "    epoch_acc = num_correct.item() / num_tokens\n",
    "    print(\"Training Epoch # {} Loss: {:.2f} Acc: {:.2f}\".format(i+1, epoch_loss.item(), epoch_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, pred_seq = model(test_src.to(device))\n",
    "score.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(src_itos[x] for x in test_src.squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold\n",
    "\" \".join(tgt_itos[x] for x in test_tgt.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred\n",
    "\" \".join(tgt_itos[x] for x in torch.cat(pred_seq, 0).tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
