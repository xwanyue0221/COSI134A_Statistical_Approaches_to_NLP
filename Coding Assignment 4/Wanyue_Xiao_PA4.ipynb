{"cells":[{"cell_type":"markdown","metadata":{"id":"wmUELGBzFUl3"},"source":["# PA4 Notebook\n","COSI-134A: StatNLP\n","\n","Wanyue Xiao"],"id":"wmUELGBzFUl3"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13436,"status":"ok","timestamp":1639771148551,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"ooBpsKEuFWs4","outputId":"a77e66f7-4ab1-4a6d-dfd1-af694e1805b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"ooBpsKEuFWs4"},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1639771148552,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"JLjAie73Gc5F","outputId":"1f8a2f89-4b0a-415f-b63c-70be76543804"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/PA4\n"]}],"source":["%cd /content/drive/My Drive/PA4/"],"id":"JLjAie73Gc5F"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1639771148552,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"yX1bzjYiF1SW","outputId":"4e0c7732-dfcb-4d4a-fd19-d0e278911279"},"outputs":[{"output_type":"stream","name":"stdout","text":[" consts.py\t   ptb\t\t\t       requirements_with_versions.txt\n"," data_loader.py   'ptb.zip (Unzipped Files)'   seq2seq.py\n"," EVALB\t\t   __pycache__\t\t       train.py\n"," inference.py\t   README.ipynb\t\t       utils.py\n"," outputs\t   README.md\t\t       vocabs.py\n"," prepare_data.py   requirements.txt\t       Wanyue_Xiao_PA4.ipynb\n"]}],"source":["!ls"],"id":"yX1bzjYiF1SW"},{"cell_type":"markdown","metadata":{"id":"C4sNmfDLFUl5"},"source":["## Contents\n","0. Introduction\n","2. Prepare Data\n","3. Seq2Seq with Attention\n","4. Training\n","5. Inference"],"id":"C4sNmfDLFUl5"},{"cell_type":"markdown","metadata":{"id":"vHf508jqFUl6"},"source":["## 0. Introduction"],"id":"vHf508jqFUl6"},{"cell_type":"markdown","metadata":{"id":"PTN9JkwTFUl7"},"source":["* this notebook is designed primarily for those using Google Colab Notebooks\n","    * you don't need to use this if you'd rather work with .py files\n","    * it may help nevertheless to look at .py files because we import and use them here\n","* make sure to read [README](./README.ipynb) before you begin\n","* entire notebook trains Vanilla Seq2Seq out-of-the-box\n","* for questions: [jchun@brandeis.edu](mailto:jchun@brandeis.edu)"],"id":"PTN9JkwTFUl7"},{"cell_type":"markdown","metadata":{"id":"Ss6hfbnRFUl8"},"source":["### Using GCP"],"id":"Ss6hfbnRFUl8"},{"cell_type":"markdown","metadata":{"id":"VYMRI3guFUl9"},"source":["* make sure to add all .py files in Colab's **Files** tab\n","* instead of importing from `seq2seq.py`, we will use the models defined in this notebook\n","    * write your implementations for attentional decoders here"],"id":"VYMRI3guFUl9"},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4611,"status":"ok","timestamp":1639771153160,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"L-A9uJKDFUl9","outputId":"82ba8ae4-af68-423f-e836-2e961966078b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (3.2.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.19.5)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.10.0+cu111)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (4.62.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->-r requirements.txt (line 1)) (1.15.0)\n","Collecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->-r requirements.txt (line 3)) (2019.12.20)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->-r requirements.txt (line 3)) (0.8.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 4)) (3.10.0.2)\n","Installing collected packages: portalocker, colorama, sacrebleu\n","Successfully installed colorama-0.4.4 portalocker-2.3.2 sacrebleu-2.0.0\n"]}],"source":["# # uncomment to download required packages \n","# # consider `requirements_with_versions.txt` if you'd like version constraints\n","!pip install -r requirements.txt"],"id":"L-A9uJKDFUl9"},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"elapsed":1065,"status":"ok","timestamp":1639771154221,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"HFBjqtPxFUl_","outputId":"a637185f-5a48-4652-d8fe-916cbb683e0f"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'3.2.5'"]},"metadata":{},"execution_count":6}],"source":["import nltk\n","nltk.__version__"],"id":"HFBjqtPxFUl_"},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"elapsed":5619,"status":"ok","timestamp":1639771159836,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"OpjUzLG_FUmA","outputId":"08d018e9-b0e0-4806-9ade-5cd882d888e1"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.10.0+cu111'"]},"metadata":{},"execution_count":7}],"source":["import torch\n","torch.__version__"],"id":"OpjUzLG_FUmA"},{"cell_type":"markdown","metadata":{"id":"xMTh6kmmFUmA"},"source":["## 1. Prepare data"],"id":"xMTh6kmmFUmA"},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1639771159837,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"tlv83af5FUmB"},"outputs":[],"source":["import os\n","import random"],"id":"tlv83af5FUmB"},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1190,"status":"ok","timestamp":1639771161023,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"ALsYOGb1FUmB"},"outputs":[],"source":["import vocabs\n","from prepare_data import linearize_parse_tree, prepare_data, process_sent"],"id":"ALsYOGb1FUmB"},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1639771161023,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"lMftS5pFFUmB"},"outputs":[],"source":["# prepare_data path hyperparams\n","PTB_DIR = './ptb'\n","DATA_DIR = './outputs/ptb'"],"id":"lMftS5pFFUmB"},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":601},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1639771161024,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"G33Jy4k0FUmC","outputId":"a003b474-ed10-45a9-f6a0-939ec1ab017d"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/PA4/ptb'"]},"metadata":{},"execution_count":11}],"source":["os.path.abspath(PTB_DIR)"],"id":"G33Jy4k0FUmC"},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1639771161024,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"rY1vHjx6FUmC","outputId":"9f3aaeb5-d450-4970-dcd1-46c60fc1b9de"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":12}],"source":["os.path.exists(PTB_DIR)"],"id":"rY1vHjx6FUmC"},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":737},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1639771161024,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"BNmrAaCwFUmD","outputId":"206fc893-6eb7-469d-d83c-6be4d20133f5"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/PA4/outputs/ptb'"]},"metadata":{},"execution_count":13}],"source":["os.path.abspath(DATA_DIR)"],"id":"BNmrAaCwFUmD"},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1639771161024,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"6jh1o17SFUmD"},"outputs":[],"source":["os.makedirs(DATA_DIR, exist_ok=True)"],"id":"6jh1o17SFUmD"},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1639771161024,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"FiZZkaEiFUmD"},"outputs":[],"source":["# prepare_data hyperparams\n","LOWER = False\n","REVERSE_SENT = False\n","PRUNE = False\n","XX_NORM = False\n","CLOSING_TAG = False\n","KEEP_INDEX = False"],"id":"FiZZkaEiFUmD"},{"cell_type":"markdown","metadata":{"id":"EU1SHy1qFUmE"},"source":["### Prepare Data Playground"],"id":"EU1SHy1qFUmE"},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1639771161025,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"dCALysJyFUmE"},"outputs":[],"source":["reader = nltk.corpus.BracketParseCorpusReader(f'{PTB_DIR}/dev', r'.*/wsj_.*\\.mrg')"],"id":"dCALysJyFUmE"},{"cell_type":"markdown","metadata":{"id":"Z5CabmsWFUmE"},"source":["#### Original Sentence"],"id":"Z5CabmsWFUmE"},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":487,"status":"ok","timestamp":1639771161507,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"ExR-jTPGFUmE","outputId":"0bc61bdd-9ce8-4e1a-ed33-6d409b3d5a05"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"Influential members of the House Ways and Means Committee introduced legislation that *T*-1 would restrict how the new savings-and-loan bailout agency can raise capital *T*-2 , *-3 creating another potential obstacle to the government 's sale of sick thrifts .\""]},"metadata":{},"execution_count":17}],"source":["sample_sent = reader.sents()[0]\n","\" \".join(sample_sent)"],"id":"ExR-jTPGFUmE"},{"cell_type":"markdown","metadata":{"id":"WeRO4lAiFUmF"},"source":["#### Preprocessed Sentence"],"id":"WeRO4lAiFUmF"},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1639771161507,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"iCsl6M8HFUmF","outputId":"48021c4f-d760-4bc2-9cf7-3b9c9b1f8a41"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"Influential members of the House Ways and Means Committee introduced legislation that *T* would restrict how the new savings-and-loan bailout agency can raise capital *T* , * creating another potential obstacle to the government 's sale of sick thrifts .\""]},"metadata":{},"execution_count":18}],"source":["# current setting\n","process_sent(sample_sent, lower=LOWER, reverse=REVERSE_SENT, keep_index=KEEP_INDEX)"],"id":"iCsl6M8HFUmF"},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1639771161508,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"q-wBcmA-FUmG","outputId":"05b0af51-2d27-4004-e8c2-925ed013b13d"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"Influential members of the House Ways and Means Committee introduced legislation that *T*-1 would restrict how the new savings-and-loan bailout agency can raise capital *T*-2 , *-3 creating another potential obstacle to the government 's sale of sick thrifts .\""]},"metadata":{},"execution_count":19}],"source":["process_sent(sample_sent, lower=False, reverse=False, keep_index=True)"],"id":"q-wBcmA-FUmG"},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1639771161508,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"hvqryQMdFUmG","outputId":"d84c4b75-f6a2-470f-b5c1-0489786f87e0"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\". thrifts sick of sale 's government the to obstacle potential another creating * , *T* capital raise can agency bailout savings-and-loan new the how restrict would *T* that legislation introduced Committee Means and Ways House the of members Influential\""]},"metadata":{},"execution_count":20}],"source":["process_sent(sample_sent, lower=False, reverse=True, keep_index=False)"],"id":"hvqryQMdFUmG"},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1639771161508,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"WOFLr9WnFUmG","outputId":"7d20396b-f79e-4510-cc24-f05639cbceb6"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"influential members of the house ways and means committee introduced legislation that *T* would restrict how the new savings-and-loan bailout agency can raise capital *T* , * creating another potential obstacle to the government 's sale of sick thrifts .\""]},"metadata":{},"execution_count":21}],"source":["process_sent(sample_sent, lower=True, reverse=False, keep_index=False)"],"id":"WOFLr9WnFUmG"},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1639771161508,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"xNZf4CUYFUmG","outputId":"109a95a6-383d-409b-d2a2-4877f1be718e"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\". thrifts sick of sale 's government the to obstacle potential another creating * , *T* capital raise can agency bailout savings-and-loan new the how restrict would *T* that legislation introduced committee means and ways house the of members influential\""]},"metadata":{},"execution_count":22}],"source":["process_sent(sample_sent, lower=True, reverse=True, keep_index=False)"],"id":"xNZf4CUYFUmG"},{"cell_type":"markdown","metadata":{"id":"AZgmlG7xFUmH"},"source":["#### Original Parse Tree"],"id":"AZgmlG7xFUmH"},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":219,"status":"ok","timestamp":1639771161723,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"E81XSmrbFUmH"},"outputs":[],"source":["sample_tree = reader.parsed_sents()[0]"],"id":"E81XSmrbFUmH"},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1639771161724,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"5PqB1VEtFUmH","outputId":"b3b493b1-26d0-457c-aae5-34d5a6ef4ef1"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"(S (NP-SBJ (NP (JJ Influential) (NNS members)) (PP (IN of) (NP (DT the) (NNP House) (NNP Ways) (CC and) (NNP Means) (NNP Committee)))) (VP (VBD introduced) (NP (NP (NN legislation)) (SBAR (WHNP-1 (WDT that)) (S (NP-SBJ-3 (-NONE- *T*-1)) (VP (MD would) (VP (VB restrict) (SBAR (WHADVP-2 (WRB how)) (S (NP-SBJ (DT the) (JJ new) (NN savings-and-loan) (NN bailout) (NN agency)) (VP (MD can) (VP (VB raise) (NP (NN capital)) (ADVP-MNR (-NONE- *T*-2)))))) (, ,) (S-ADV (NP-SBJ (-NONE- *-3)) (VP (VBG creating) (NP (NP (DT another) (JJ potential) (NN obstacle)) (PP (TO to) (NP (NP (NP (DT the) (NN government) (POS 's)) (NN sale)) (PP (IN of) (NP (JJ sick) (NNS thrifts)))))))))))))) (. .))\""]},"metadata":{},"execution_count":24}],"source":["\" \".join(str(sample_tree).strip().split())"],"id":"5PqB1VEtFUmH"},{"cell_type":"markdown","metadata":{"id":"v2trFqsfFUmH"},"source":["#### Preprocessed Parse Tree"],"id":"v2trFqsfFUmH"},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1639771161724,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"LCwTtBNtFUmH","outputId":"bc116167-5f03-4cfd-9505-ea4a7372f1ea"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'(S (NP-SBJ (NP (JJ ) (NNS ) ) (PP (IN ) (NP (DT ) (NNP ) (NNP ) (CC ) (NNP ) (NNP ) ) ) ) (VP (VBD ) (NP (NP (NN ) ) (SBAR (WHNP (WDT ) ) (S (NP-SBJ (-NONE- ) ) (VP (MD ) (VP (VB ) (SBAR (WHADVP (WRB ) ) (S (NP-SBJ (DT ) (JJ ) (NN ) (NN ) (NN ) ) (VP (MD ) (VP (VB ) (NP (NN ) ) (ADVP-MNR (-NONE- ) ) ) ) ) ) (, ) (S-ADV (NP-SBJ (-NONE- ) ) (VP (VBG ) (NP (NP (DT ) (JJ ) (NN ) ) (PP (TO ) (NP (NP (NP (DT ) (NN ) (POS ) ) (NN ) ) (PP (IN ) (NP (JJ ) (NNS ) ) ) ) ) ) ) ) ) ) ) ) ) ) (. ) )'"]},"metadata":{},"execution_count":25}],"source":["# current setting\n","linearize_parse_tree(sample_tree, prune_leaf_brackets=PRUNE, XX_norm=XX_NORM, closing_tag=CLOSING_TAG, keep_index=KEEP_INDEX)"],"id":"LCwTtBNtFUmH"},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1639771161724,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"fISFiyXZFUmI","outputId":"169dc873-e997-4a67-d2a8-6bb309c027b2"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'(S (NP-SBJ (NP (JJ ) (NNS ) ) (PP (IN ) (NP (DT ) (NNP ) (NNP ) (CC ) (NNP ) (NNP ) ) ) ) (VP (VBD ) (NP (NP (NN ) ) (SBAR (WHNP-1 (WDT ) ) (S (NP-SBJ-3 (-NONE- ) ) (VP (MD ) (VP (VB ) (SBAR (WHADVP-2 (WRB ) ) (S (NP-SBJ (DT ) (JJ ) (NN ) (NN ) (NN ) ) (VP (MD ) (VP (VB ) (NP (NN ) ) (ADVP-MNR (-NONE- ) ) ) ) ) ) (, ) (S-ADV (NP-SBJ (-NONE- ) ) (VP (VBG ) (NP (NP (DT ) (JJ ) (NN ) ) (PP (TO ) (NP (NP (NP (DT ) (NN ) (POS ) ) (NN ) ) (PP (IN ) (NP (JJ ) (NNS ) ) ) ) ) ) ) ) ) ) ) ) ) ) (. ) )'"]},"metadata":{},"execution_count":26}],"source":["linearize_parse_tree(\n","    sample_tree, prune_leaf_brackets=False, XX_norm=False, closing_tag=False, keep_index=True)"],"id":"fISFiyXZFUmI"},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1639771161724,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"r4E9BgEvFUmI","outputId":"ef3470a3-c0c1-4fe4-92a9-e8f80c83fd89"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'(S (NP-SBJ (NP (JJ )JJ (NNS )NNS )NP (PP (IN )IN (NP (DT )DT (NNP )NNP (NNP )NNP (CC )CC (NNP )NNP (NNP )NNP )NP )PP )NP-SBJ (VP (VBD )VBD (NP (NP (NN )NN )NP (SBAR (WHNP (WDT )WDT )WHNP (S (NP-SBJ (-NONE- )-NONE- )NP-SBJ (VP (MD )MD (VP (VB )VB (SBAR (WHADVP (WRB )WRB )WHADVP (S (NP-SBJ (DT )DT (JJ )JJ (NN )NN (NN )NN (NN )NN )NP-SBJ (VP (MD )MD (VP (VB )VB (NP (NN )NN )NP (ADVP-MNR (-NONE- )-NONE- )ADVP-MNR )VP )VP )S )SBAR (, ), (S-ADV (NP-SBJ (-NONE- )-NONE- )NP-SBJ (VP (VBG )VBG (NP (NP (DT )DT (JJ )JJ (NN )NN )NP (PP (TO )TO (NP (NP (NP (DT )DT (NN )NN (POS )POS )NP (NN )NN )NP (PP (IN )IN (NP (JJ )JJ (NNS )NNS )NP )PP )NP )PP )NP )VP )S-ADV )VP )VP )S )SBAR )NP )VP (. ). )S'"]},"metadata":{},"execution_count":27}],"source":["linearize_parse_tree(\n","    sample_tree, prune_leaf_brackets=False, XX_norm=False, closing_tag=True, keep_index=False)"],"id":"r4E9BgEvFUmI"},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1639771161724,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"AHIo6GUdFUmI","outputId":"beb6480c-4edc-4b98-eb16-c776949551f4"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'(XX (XX (XX (XX ) (XX ) ) (XX (XX ) (XX (XX ) (XX ) (XX ) (XX ) (XX ) (XX ) ) ) ) (XX (XX ) (XX (XX (XX ) ) (XX (XX (XX ) ) (XX (XX (XX ) ) (XX (XX ) (XX (XX ) (XX (XX (XX ) ) (XX (XX (XX ) (XX ) (XX ) (XX ) (XX ) ) (XX (XX ) (XX (XX ) (XX (XX ) ) (XX (XX ) ) ) ) ) ) (XX ) (XX (XX (XX ) ) (XX (XX ) (XX (XX (XX ) (XX ) (XX ) ) (XX (XX ) (XX (XX (XX (XX ) (XX ) (XX ) ) (XX ) ) (XX (XX ) (XX (XX ) (XX ) ) ) ) ) ) ) ) ) ) ) ) ) ) (XX ) )'"]},"metadata":{},"execution_count":28}],"source":["linearize_parse_tree(\n","    sample_tree, prune_leaf_brackets=False, XX_norm=True, closing_tag=False, keep_index=False)"],"id":"AHIo6GUdFUmI"},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1639771161725,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"XDwWHkGIFUmJ","outputId":"f4be84f8-878f-4717-fccf-ef48519dc2fc"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'(S (NP-SBJ (NP JJ NNS ) (PP IN (NP DT NNP NNP CC NNP NNP ) ) ) (VP VBD (NP (NP NN ) (SBAR (WHNP WDT ) (S (NP-SBJ -NONE- ) (VP MD (VP VB (SBAR (WHADVP WRB ) (S (NP-SBJ DT JJ NN NN NN ) (VP MD (VP VB (NP NN ) (ADVP-MNR -NONE- ) ) ) ) ) , (S-ADV (NP-SBJ -NONE- ) (VP VBG (NP (NP DT JJ NN ) (PP TO (NP (NP (NP DT NN POS ) NN ) (PP IN (NP JJ NNS ) ) ) ) ) ) ) ) ) ) ) ) ) . )'"]},"metadata":{},"execution_count":29}],"source":["linearize_parse_tree(\n","    sample_tree, prune_leaf_brackets=True, XX_norm=False, closing_tag=False, keep_index=False)"],"id":"XDwWHkGIFUmJ"},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1639771161725,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"AM-ju8cxFUmJ","outputId":"776896af-3f4d-4cc9-e83e-ef71fbf84e7f"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'(XX (XX (XX XX XX ) (XX XX (XX XX XX XX XX XX XX ) ) ) (XX XX (XX (XX XX ) (XX (XX XX ) (XX (XX XX ) (XX XX (XX XX (XX (XX XX ) (XX (XX XX XX XX XX XX ) (XX XX (XX XX (XX XX ) (XX XX ) ) ) ) ) XX (XX (XX XX ) (XX XX (XX (XX XX XX XX ) (XX XX (XX (XX (XX XX XX XX ) XX ) (XX XX (XX XX XX ) ) ) ) ) ) ) ) ) ) ) ) ) XX )'"]},"metadata":{},"execution_count":30}],"source":["linearize_parse_tree(\n","    sample_tree, prune_leaf_brackets=True, XX_norm=True, closing_tag=False, keep_index=False)"],"id":"AM-ju8cxFUmJ"},{"cell_type":"markdown","metadata":{"id":"y-BU-zgfFUmK"},"source":["### Run Prepare Data\n","* preprocess both sentence and parse tree data\n","* compile vocab counters"],"id":"y-BU-zgfFUmK"},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":650902,"status":"ok","timestamp":1639771812622,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"Fo0N17wiFUmK","outputId":"5d2661a0-e7e2-4e22-ce5b-229914e99dfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Begin loading and processing PTB..\n","\n","Loading dev..\n"]},{"output_type":"stream","name":"stderr","text":["[Processing Sents]: 100%|██████████| 1700/1700 [00:00<00:00, 2215.62it/s]\n","[Processing Trees]: 100%|██████████| 1700/1700 [00:02<00:00, 632.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Sample ptb from dev\n","  Sent: Influential members of the House Ways and Means Committee introduced legislation that *T* would restrict how the new savings-and-loan bailout agency can raise capital *T* , * creating another potential obstacle to the government 's sale of sick thrifts .\n","  Tree: (S (NP-SBJ (NP (JJ ) (NNS ) ) (PP (IN ) (NP (DT ) (NNP ) (NNP ) (CC ) (NNP ) (NNP ) ) ) ) (VP (VBD ) (NP (NP (NN ) ) (SBAR (WHNP (WDT ) ) (S (NP-SBJ (-NONE- ) ) (VP (MD ) (VP (VB ) (SBAR (WHADVP (WRB ) ) (S (NP-SBJ (DT ) (JJ ) (NN ) (NN ) (NN ) ) (VP (MD ) (VP (VB ) (NP (NN ) ) (ADVP-MNR (-NONE- ) ) ) ) ) ) (, ) (S-ADV (NP-SBJ (-NONE- ) ) (VP (VBG ) (NP (NP (DT ) (JJ ) (NN ) ) (PP (TO ) (NP (NP (NP (DT ) (NN ) (POS ) ) (NN ) ) (PP (IN ) (NP (JJ ) (NNS ) ) ) ) ) ) ) ) ) ) ) ) ) ) (. ) )\n","\n","Loading train..\n"]},{"output_type":"stream","name":"stderr","text":["[Processing Sents]: 100%|██████████| 39832/39832 [00:16<00:00, 2344.65it/s]\n","[Processing Trees]: 100%|██████████| 39832/39832 [00:44<00:00, 899.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Sample ptb from train\n","  Sent: In an Oct. !DIGITS review of `` The Misanthrope '' at Chicago 's Goodman Theatre -LRB- `` Revitalized Classics Take the Stage in Windy City , '' Leisure & Arts -RRB- , the role of Celimene , played * by Kim Cattrall , was mistakenly attributed * to Christina Haag .\n","  Tree: (S (PP-LOC (IN ) (NP (NP (DT ) (NNP ) (CD ) (NN ) ) (PP (IN ) (NP (`` ) (NP-TTL (DT ) (NN ) ) ('' ) (PP-LOC (IN ) (NP (NP (NNP ) (POS ) ) (NNP ) (NNP ) ) ) ) ) (PRN (-LRB- ) (`` ) (S-HLN (NP-SBJ (VBN ) (NNS ) ) (VP (VBP ) (NP (DT ) (NN ) ) (PP-LOC (IN ) (NP (NNP ) (NNP ) ) ) ) ) (, ) ('' ) (NP-TMP (NN ) (CC ) (NNS ) ) (-RRB- ) ) ) ) (, ) (NP-SBJ (NP (NP (DT ) (NN ) ) (PP (IN ) (NP (NNP ) ) ) ) (, ) (VP (VBN ) (NP (-NONE- ) ) (PP (IN ) (NP-LGS (NNP ) (NNP ) ) ) ) (, ) ) (VP (VBD ) (VP (ADVP-MNR (RB ) ) (VBN ) (NP (-NONE- ) ) (PP-CLR (TO ) (NP (NNP ) (NNP ) ) ) ) ) (. ) )\n","\n","Compiling Vocab..\n","\n","Vocab Info:\n","  Sent (39175) => ,, the, ., !DIGITS, *, of, to, a, and, *T*, in, 's, that, for, *U*, $, ``, is, The, '', said, on, %, it, by, from, million, at, as, with, Mr., was, be, are, its, has, n't, an, will, have, !YEAR, he, or, company, year, which, would, about, --, says, they, were, this, market, more, billion, had, But, In, his, up, their, but, than, U.S., been, who, share, also, new, one, other, :, not, some, Corp., stock, I, years, New, shares, -RRB-, It, -LRB-, ;, could, all, Inc., last, two, out, &, trading, *ICH*, because, when, sales, do, only, after, ...\n","  Tree (293) => ), (NP, (VP, (NN, (IN, (NP-SBJ, (NNP, (S, (DT, (-NONE-, (JJ, (NNS, (PP, (,, (., (CD, (RB, (VBD, (VB, (CC, (SBAR, (TO, (VBZ, (VBN, (PRP, (VBG, (PP-LOC, (VBP, (PP-CLR, (ADVP, (MD, (QP, (WHNP, (POS, (PRP$, (PP-TMP, (ADJP, ($, (``, ('', (ADJP-PRD, (ADVP-TMP, (NP-PRD, (:, (PP-DIR, (NP-TMP, (WDT, (S-TPC, (JJR, (S-NOM, (SBAR-ADV, (NNPS, (RP, (PRT, (WHADVP, (NP-LGS, (ADVP-MNR, (PRN, (WP, (SBAR-TMP, (S-ADV, (WRB, (SINV, (NP-ADV, (JJS, (RBR, (NP-EXT, (PP-MNR, (-RRB-, (-LRB-, (S-PRP, (NX, (ADVP-LOC, (SBAR-PRP, (PP-PRD, (EX, (PP-PRP, (PP-LOC-CLR, (ADVP-CLR, (S-CLR, (NP-LOC, (ADVP-DIR, (PP-LOC-PRD, (FRAG, (SBAR-NOM, (ADVP-PRD, (RBS, (PP-DTV, (WHPP, (PDT, (SBAR-PRD, (SQ, (UCP, (CONJP, (NP-TTL, (S-NOM-SBJ, (NP-HLN, (FW, (NAC-LOC, (PP-EXT, (S-PRD, (SBARQ, (PP-PUT, (NP-CLR, (WP$, (ADVP-PRP, (X, (NAC, (ADVP-LOC-PRD, (#, (S-HLN, (INTJ, (SBAR-NOM-SBJ, (UH, (NP-TMP-CLR, (UCP-PRD, (S-PRP-CLR, (ADVP-EXT, (PP-TMP-CLR, (NX-TTL, (WHADJP, (SYM, (VP-TPC, (S-TTL, (S-CLF, (ADVP-LOC-CLR, (ADJP-CLR, (SBAR-SBJ, (SBAR-CLR, (RRC, (NP-MNR, (NP-TTL-SBJ, (SBAR-MNR, (SBAR-LOC, (PP-LOC-PRD-TPC, (S-MNR, (LST, (PP-TPC, (LS, (PP-BNF, (SBAR-NOM-PRD, (ADVP-LOC-PRD-TPC, (ADVP-PUT, (SBAR-PRP-PRD, (ADJP-PRD-TPC, (PP-LGS, (PP-TMP-PRD, (NAC-TMP, (NP-TPC, (NP-VOC, (ADJP-ADV, (PP-DIR-CLR, (UCP-LOC, (ADVP-PRD-TPC, (S-TMP, (S-SBJ, (UCP-TMP, (ADVP-TMP-CLR, (NP-TTL-PRD, (FRAG-TPC, (SBARQ-TPC, (NP-DIR, (PP-CLR-LOC, (S-NOM-PRD, (UCP-PRP, (SBAR-LOC-PRD, (SBAR-TPC, (PP-PRD-TPC, (NP-BNF, (PP-PRP-PRD, (ADVP-TMP-PRD, (PP-PRD-LOC, (PP-TTL, (FRAG-ADV, (ADJP-TPC, (UCP-CLR, (NP-TMP-HLN, (NP-LOC-PRD, (UCP-MNR, (PP-LOC-CLR-TPC, (NAC-TTL, (ADVP-TPC, (SBAR-NOM-LGS, (SQ-TPC, (X-ADV, (UCP-ADV, (NP-TMP-PRD, (PP-LOC-TPC, (NP-LOC-CLR, (FRAG-HLN, (NP-PRD-TPC, (S-NOM-LGS, (PP-DIR-PRD, (PP-LOC-HLN, (SBAR-TMP-PRD, (ADVP-LOC-TPC, (ADVP-DIR-CLR, (SBAR-PUT, (SBAR-NOM-TPC, (SQ-PRD, (SBARQ-PRD, (ADVP-MNR-CLR, (SINV-TPC, (SBAR-TTL, (PP-CLR-TPC, (UCP-DIR, (SBAR-DIR, (PP-NOM, (SBAR-TMP-CLR, (S-TTL-PRD, (S-PRP-TPC, (SBARQ-HLN, (VP-TTL, (NP-PRD-TTL, (PP-HLN, (SQ-TTL, (X-HLN, (ADVP-CLR-TPC, (ADJP-SBJ, (ADVP-DIR-TPC, (PP-TTL-PRD, (ADVP-LOC-TMP, (ADJP-LOC, (SBAR-LOC-CLR, (PP-PRP-CLR, (FRAG-TTL, (INTJ-CLR, (PP-MNR-PRD, (NP-LOC-HLN, (NP-SBJ-TTL, (S-MNR-CLR, (ADVP-LOC-TPC-PRD, (PP-SBJ, (X-TMP, (X-TTL, (WHADVP-TMP, (SBAR-PRD-TPC, (PP-PRD-LOC-TPC, (S-PRD-TPC, (ADVP-PRD-LOC-TPC, (S-TPC-TMP, (NP-CLR-TMP, (PP-CLR-TMP, (UCP-LOC-PRD, (NP-CLR-LOC, (ADVP-PRD-TMP, (UCP-EXT, (UCP-PRD-LOC, (NP-LOC-TPC-PRD, (SBAR-HLN, (SBARQ-TTL, (ADVP-MNR-TMP, (ADVP-LOC-CLR-TPC, (NP-MNR-CLR, (SINV-TTL, (S-TTL-SBJ, (ADVP-PUT-TPC, (UCP-TPC, (S-CLR-ADV, (PRT|ADVP, (S-PRP-PRD, (ADVP-TMP-TPC, (INTJ-HLN, (ADVP-CLR-MNR, (ADJP-MNR, (ADVP-MNR-TPC, (PP-LOC-TPC-PRD, (SINV-HLN, (S-LOC, (FRAG-PRD, (PP-TPC-CLR, (SBAR-ADV-TPC, (X-CLF, (PP-TMP-TPC, (NP-TTL-TPC, (PP-TPC-LOC-PRD, (PP-LOC-MNR, (PP-TPC-PRD, (SBARQ-NOM, (SINV-ADV, (X-DIR, (SBAR-DIR-TPC, (X-PUT, (S-CLF-TPC, (ADVP-TPC-PRD, (X-EXT, (ADVP-PRD-LOC, (ADJP-HLN, (UCP-HLN, (ADJP-TTL, (PP-MNR-CLR, (SBAR-MNR-PRD, (S-TMP-TPC\n","\n","Loading test..\n"]},{"output_type":"stream","name":"stderr","text":["[Processing Sents]: 100%|██████████| 2416/2416 [00:00<00:00, 2417.46it/s]\n","[Processing Trees]: 100%|██████████| 2416/2416 [00:02<00:00, 912.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Sample ptb from test\n","  Sent: No , it was n't Black Monday .\n","  Tree: (S (INTJ (RB ) ) (, ) (NP-SBJ (PRP ) ) (VP (VBD ) (RB ) (NP-PRD (NNP ) (NNP ) ) ) (. ) )\n"]}],"source":["datasets, vocab_counters = prepare_data(ptb_dir=PTB_DIR, out_dir=DATA_DIR, lower=LOWER, reverse_sent=REVERSE_SENT, prune_leaf_brackets=PRUNE, XX_norm=XX_NORM, closing_tag=CLOSING_TAG, keep_index=KEEP_INDEX)"],"id":"Fo0N17wiFUmK"},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1639771812624,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"RSx9JPSkFUmK"},"outputs":[],"source":["dev_raw, train_raw, test_raw = datasets"],"id":"RSx9JPSkFUmK"},{"cell_type":"markdown","metadata":{"id":"3YdTuLQiFUmK"},"source":["## 2. Seq2Seq with Attention"],"id":"3YdTuLQiFUmK"},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1639771812625,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"ZHUyVZ5cFUmK"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","import consts as C"],"id":"ZHUyVZ5cFUmK"},{"cell_type":"markdown","metadata":{"id":"Flp6xRK2FUmL"},"source":["### A. Encoder"],"id":"Flp6xRK2FUmL"},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1639771812626,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"mw-Mv1HJFUmL"},"outputs":[],"source":["class Encoder(nn.Module):\n","    \"\"\"Recurrent Encoder\"\"\"\n","    def __init__(self, sent_stoi, embed_dim, hidden_dim, num_layers, dropout, rnn_type):\n","        \"\"\"configs and layers for Encoder\n","\n","        Args:\n","          tree_stoi: tree str-to-int vocab\n","          embed_dim: embedding feature dimension\n","          hidden_dim: RNN hidden dimension\n","          num_layers: number of RNN layers\n","          dropout: dropout probability\n","          rnn_type: RNN, GRU or LSTM\n","        \"\"\"\n","        super().__init__()\n","        ### configs\n","        self.rnn_type = rnn_type\n","\n","        ### layers\n","        self.embedding = nn.Embedding(len(sent_stoi), embed_dim, padding_idx=sent_stoi[C.PAD])\n","        self.dropout = nn.Dropout(dropout)\n","        if rnn_type == C.GRU:\n","            self.rnn = nn.GRU(embed_dim, hidden_dim, num_layers, batch_first=True)\n","        elif rnn_type == C.LSTM:\n","            self.rnn = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n","        else:\n","            self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers, batch_first=True)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        for name, param in self.rnn.named_parameters():\n","            if 'weight' in name:\n","                nn.init.xavier_uniform_(param)\n","            elif 'bias' in name:\n","                nn.init.constant_(param, 0.)\n","\n","    def init_pretrained_embedding(self, weights, finetune=False):\n","        \"\"\"initializes nn.Embedding layer with pre-trained embedding weights\n","\n","        Args:\n","          weights: GloVe embedding vector\n","          finetune: whether to finetune the embedding matrix during training\n","        \"\"\"\n","        self.embedding = nn.Embedding.from_pretrained(weights, freeze=not finetune)\n","\n","    def forward(self, x, lengths):\n","        \"\"\"encodes source sentences\n","\n","        Args:\n","          x: source tensor, (batch_size, sent_seq_len)\n","          lengths: valid source length list, (batch_size)\n","\n","        Returns:\n","          outputs: RNN hidden states for all time-steps, (batch_size, sent_seq_len, hidden_dim)\n","          state: last RNN hidden state\n","            if RNN or GRU:  (num_layers, batch_size, hidden_dim)\n","            if LSTM: Tuple((num_layers, batch_size, hidden_dim),\n","                           (num_layers, batch_size, hidden_dim))\n","        \"\"\"\n","        # (batch_size, src_seq_len, embed_size)\n","        x = self.dropout(self.embedding(x))\n","        x = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n","        outputs, state = self.rnn(x)\n","        # output: (batch_size, src_seq_len, hidden_dim)\n","        outputs, _ = pad_packed_sequence(outputs, batch_first=True)\n","        return outputs, state"],"id":"mw-Mv1HJFUmL"},{"cell_type":"markdown","metadata":{"id":"ZenFNHLrFUmM"},"source":["### B. Vanilla Decoder"],"id":"ZenFNHLrFUmM"},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1639771812627,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"wbEGnYcBFUmN"},"outputs":[],"source":["class Decoder(nn.Module):\n","    \"\"\"Vanilla Recurrent Decoder\"\"\"\n","    def __init__(self, tree_stoi, embed_dim, hidden_dim, num_layers, dropout, rnn_type):\n","        \"\"\"configs and layers for Vanilla Decoder\n","\n","        Args:\n","          tree_stoi: tree str-to-int vocab\n","          embed_dim: embedding feature dimension\n","          hidden_dim: RNN hidden dimension\n","          num_layers: number of RNN layers\n","          dropout: dropout probability\n","          rnn_type: RNN, GRU or LSTM\n","        \"\"\"\n","        super().__init__()\n","        ### configs\n","        vocab_size = len(tree_stoi)\n","\n","        ### layers\n","        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=tree_stoi[C.PAD])\n","        self.dropout = nn.Dropout(dropout)\n","        if rnn_type == C.GRU:\n","            self.rnn = nn.GRU(embed_dim, hidden_dim, num_layers, batch_first=True)\n","        elif rnn_type == C.LSTM:\n","            self.rnn = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n","        else:\n","            self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers, batch_first=True)\n","        self.dense = nn.Linear(hidden_dim, vocab_size)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        for name, param in self.rnn.named_parameters():\n","            if 'weight' in name:\n","                nn.init.xavier_uniform_(param)\n","            elif 'bias' in name:\n","                nn.init.constant_(param, 0.)\n","        nn.init.xavier_uniform_(self.dense.weight)\n","        nn.init.constant_(self.dense.bias, 0.)\n","\n","    def forward(self, x, state, *args):\n","        \"\"\"decodes for `tgt_seq_len` number of steps\n","\n","        when `tgt_seq_len` == 1, we decode for one time-step. This is useful\n","          during inference, when not using teacher forcing\n","\n","        when `tgt_seq_len` > 1, we decode for more than one-step. This can happen\n","          only when using teacher forcing, i.e. during training\n","\n","        Args:\n","          x: target tensor, (batch_size, tgt_seq_len)\n","          state: previous hidden state\n","            if RNN or GRU:  (num_layers, batch_size, hidden_dim)\n","            if LSTM: Tuple((num_layers, batch_size, hidden_dim),\n","                           (num_layers, batch_size, hidden_dim))\n","          *args: captures other unused arguments\n","\n","        Returns:\n","          output: token-level logits, (batch_size, tgt_seq_len, vocab_size)\n","          state: decoder's last RNN hidden state. Similar shape as `state`\n","        \"\"\"\n","        # (batch_size, src_seq_len, embed_size)\n","        x = self.dropout(self.embedding(x))\n","\n","        # output: (batch_size, tgt_seq_len, hidden_dim)\n","        output, state = self.rnn(x, state)\n","\n","        # (batch_size, tgt_seq_len, vocab_size)\n","        output = self.dense(output)\n","        return output, state"],"id":"wbEGnYcBFUmN"},{"cell_type":"markdown","metadata":{"id":"WVE8n3F2FUmN"},"source":["### C. Bahdanau Attentional Decoder"],"id":"WVE8n3F2FUmN"},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1639771812826,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"tVWpqPsQFUmN"},"outputs":[],"source":["class BahdanauAttentionDecoder(nn.Module):\n","    \"\"\"Bahdanau (Additive) Attentional Decoder\n","    score = v^T \\cdot \\tanh(W_h \\cdot H_h + W_e \\cdot H_e)\n","    where H_e: encoder outputs, and H_h: previous decoder hidden state\n","    \"\"\"\n","    def __init__(self, tree_stoi, embed_dim, hidden_dim, num_layers, dropout, rnn_type):\n","        \"\"\"configs and layers for Decoder with Bahdanau Attention\n","\n","        Args:\n","          tree_stoi: tree str-to-int vocab\n","          embed_dim: embedding feature dimension\n","          hidden_dim: RNN hidden dimension\n","          num_layers: number of RNN layers\n","          dropout: dropout probability\n","          rnn_type: RNN, GRU or LSTM\n","        \"\"\"\n","        super().__init__()\n","        ### configs\n","        vocab_size = len(tree_stoi)\n","\n","        ### layers\n","        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=tree_stoi[C.PAD])\n","        self.dropout = nn.Dropout(dropout)\n","        if rnn_type == C.GRU:\n","            self.rnn = nn.GRU(embed_dim, hidden_dim, num_layers, batch_first=True)\n","        elif rnn_type == C.LSTM:\n","            self.rnn = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n","        else:\n","            self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers, batch_first=True)\n","        self.dense = nn.Linear(hidden_dim, vocab_size)\n","        \n","        self.query_compute = nn.Linear(hidden_dim, hidden_dim)\n","        self.key_compute = nn.Linear(hidden_dim, hidden_dim)\n","        self.score_compute = nn.Linear(hidden_dim, 1)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        for name, param in self.rnn.named_parameters():\n","            if 'weight' in name:\n","                nn.init.xavier_uniform_(param)\n","            elif 'bias' in name:\n","                nn.init.constant_(param, 0.)\n","        nn.init.xavier_uniform_(self.dense.weight)\n","        nn.init.constant_(self.dense.bias, 0.)\n","\n","    def forward(self, x, state, encoder_outputs, mask=None):\n","        \"\"\"single decoder step with Bahdanau attention. Additive attention takes place when the outptus of `fc_hidden` and `fc_encoder` are summed. There are other interpretations that prefer concat over addition.\n","        `x` may be a gold decoder input (with teacher forcing) or a previous decoder's prediction (without teacher forcing).\n","\n","        Args:\n","          x: decoder input, (batch_size, 1)\n","          state: decoder's previous RNN hidden state\n","            if RNN or GRU:  (num_layers, batch_size, hidden_dim)\n","            if LSTM: Tuple(\n","              (num_layers, batch_size, hidden_dim),\n","              (num_layers, batch_size, hidden_dim))\n","          encoder_outputs: RNN hidden states for all time-steps, (batch_size, src_seq_len, hidden_dim)\n","          mask: boolean tensor, (batch_size, 1)\n","\n","        Returns:\n","          output: logits, (batch_size, 1, vocab_size)\n","          state: decoder's last RNN hidden state. Similar shape as `state`\n","        \"\"\"\n","        x = self.embedding(x);\n","        output, state = self.rnn(x, state)\n","        score = self.score_compute(torch.tanh(self.query_compute(output) + self.key_compute(encoder_outputs))).squeeze(-1)\n","        attn = F.softmax(score, dim=-1)\n","        output = torch.bmm(attn.unsqueeze(1), encoder_outputs)\n","        output = self.dense(output)\n","        return output, state"],"id":"tVWpqPsQFUmN"},{"cell_type":"markdown","metadata":{"id":"9ojye3ETFUmO"},"source":["### D. Luong Attentional Decoder"],"id":"9ojye3ETFUmO"},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1639771813140,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"k512753PFUmO"},"outputs":[],"source":["class LuongAttentionDecoder(nn.Module):\n","    \"\"\"Luong (Multiplicative) Attention\n","\n","    Dot:\n","        score = H_e \\cdot H_h\n","    General:\n","        score = H_e \\cdot W \\cdot H_h\n","\n","    where H_e: encoder outputs, and H_h: previous decoder hidden state\n","\n","    There also exists Luong Concat, but you are not asked to implement it.\n","    \"\"\"\n","    def __init__(self, tree_stoi, embed_dim, hidden_dim, num_layers, dropout, rnn_type, mode):\n","        \"\"\"configs and layers for Decoder with Luong Attention\n","\n","        Args:\n","          tree_stoi: tree str-to-int vocab\n","          embed_dim: embedding feature dimension\n","          hidden_dim: RNN hidden dimension\n","          num_layers: number of RNN layers\n","          dropout: dropout probability\n","          rnn_type: RNN, GRU or LSTM\n","          mode: `dot` or `general`\n","        \"\"\"\n","        super().__init__()\n","        ### configs\n","        vocab_size = len(tree_stoi)\n","        self.mode = mode;\n","\n","        ### layers\n","        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=tree_stoi[C.PAD])\n","        self.dropout = nn.Dropout(dropout)\n","        if rnn_type == C.GRU:\n","            self.rnn = nn.GRU(embed_dim, hidden_dim, num_layers, batch_first=True)\n","        elif rnn_type == C.LSTM:\n","            self.rnn = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n","        else:\n","            self.rnn = nn.RNN(embed_dim, hidden_dim, num_layers, batch_first=True)\n","        self.dense = nn.Linear(hidden_dim, vocab_size)\n","        # general mode\n","        self.attention = nn.Linear(hidden_dim, hidden_dim)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        for name, param in self.rnn.named_parameters():\n","            if 'weight' in name:\n","                nn.init.xavier_uniform_(param)\n","            elif 'bias' in name:\n","                nn.init.constant_(param, 0.)\n","        nn.init.xavier_uniform_(self.dense.weight)\n","        nn.init.constant_(self.dense.bias, 0.)\n","\n","    def forward(self, x, state, encoder_outputs, mask=None):\n","        \"\"\"single decoder step with Luong attention\n","\n","        `x` may be a gold decoder input (with teacher forcing) or a previous decoder's\n","        prediction (without teacher forcing).\n","\n","        Args:\n","          x: decoder input, (batch_size, 1)\n","          state: decoder's previous RNN hidden state\n","            if RNN or GRU:  (num_layers, batch_size, hidden_dim)\n","            if LSTM: Tuple(\n","              (num_layers, batch_size, hidden_dim),\n","              (num_layers, batch_size, hidden_dim)\n","            )\n","          encoder_outputs: RNN hidden states for all time-steps, (batch_size, src_seq_len, hidden_dim)\n","          mask: boolean tensor, (batch_size, 1)\n","\n","        Returns:\n","          output: logits, (batch_size, 1, vocab_size)\n","          state: decoder's last RNN hidden state. Similar shape as `state`\n","        \"\"\"\n","\n","        if self.mode == 'general':\n","            x = self.embedding(x);\n","            output, state = self.rnn(x, state)\n","            attn_weights = self.attention(output)\n","            score = torch.bmm(attn_weights, encoder_outputs.transpose(-2, -1))\n","\n","            attn = F.softmax(score, dim=-1)\n","            output = torch.bmm(attn, encoder_outputs)\n","            output = self.dense(output)\n","            return output, state\n","\n","        elif self.mode == 'dot':\n","            x = self.embedding(x);\n","            output, state = self.rnn(x, state)\n","            score = torch.bmm(output, encoder_outputs.transpose(-2, -1))\n","            attn = F.softmax(score, dim=-1)\n","            output = torch.bmm(attn, encoder_outputs)\n","            output = self.dense(output)\n","            return output, state"],"id":"k512753PFUmO"},{"cell_type":"markdown","metadata":{"id":"hgRmuF3qFUmO"},"source":["### E. Seq2Seq"],"id":"hgRmuF3qFUmO"},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1639771813141,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"JyUgFxIOFUmP"},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    \"\"\"Seq2Seq\"\"\"\n","    def __init__(self, *, model, sent_stoi, tree_stoi, embed_dim, hidden_dim,\n","                 num_layers, dropout, rnn_type, glove, finetune_glove, device):\n","        super().__init__()\n","        print(f\"\\n{model.capitalize()} Seq2Seq init\")\n","\n","        ### configs\n","        self.model = model\n","\n","        self.tree_vocab_size = len(tree_stoi)\n","        self.sent_pad_idx = sent_stoi[C.PAD]\n","        self.tree_bos_idx = tree_stoi[C.BOS]\n","        self.tree_eos_idx = tree_stoi[C.EOS]\n","\n","        self.dropout = dropout\n","        self.rnn_type = rnn_type\n","\n","        ### modules\n","        self.encoder = Encoder(sent_stoi=sent_stoi, embed_dim=embed_dim, hidden_dim=hidden_dim, num_layers=num_layers, dropout=dropout, rnn_type=rnn_type)\n","        if glove is not None:\n","            self.encoder.init_pretrained_embedding(glove, finetune=finetune_glove)\n","\n","        decoder_kwargs = {'tree_stoi': tree_stoi, 'embed_dim': embed_dim, 'hidden_dim': hidden_dim, 'num_layers': num_layers, 'dropout': dropout, 'rnn_type': rnn_type}\n","        if model == C.BAHDANAU:\n","            self.decoder = BahdanauAttentionDecoder(**decoder_kwargs)\n","        elif model in [C.LUONG_DOT, C.LUONG_GENERAL]:\n","            mode = model.split('_')[-1]\n","            print(mode)\n","            self.decoder = LuongAttentionDecoder(**decoder_kwargs, mode=mode)\n","        else:\n","            self.decoder = Decoder(**decoder_kwargs)\n","\n","        self.device = device\n","\n","    def parse(self, x, x_lens):\n","        \"\"\"forward computation for inference\n","\n","        during inference we keep it simple by assuming `batch_size` == 1\n","\n","        Args:\n","          x: (1, src_seq_len)\n","          x_lens: (1)\n","\n","        Returns:\n","          predictions as list of ints\n","        \"\"\"\n","        # encode step\n","        encoder_outputs, state = self.encoder(x, x_lens)\n","\n","        # setup for decoding loop\n","        max_decode_step = x.size(1) * 3\n","\n","        # padding mask necessary for attentional decoders; not used by vanilla decoder\n","        # True if valid token, False otherwise (i.e. padding)\n","        padding_mask = x==self.sent_pad_idx\n","\n","        # (1, 1)\n","        yt = torch.tensor([[self.tree_bos_idx]], dtype=torch.long, device=self.device)\n","\n","        # decoding loop\n","        preds = []\n","        for i in range(max_decode_step):\n","            # decode step\n","            output, state = self.decoder(yt, state, encoder_outputs, padding_mask)\n","\n","            # current time-step prediction\n","            yt = output.argmax(-1)\n","            yt_int = yt.item()\n","\n","            # when parsing, no need to keep EOS in our predictions but simply terminate\n","            if yt_int == self.tree_eos_idx:\n","                break\n","            preds.append(yt_int)\n","\n","        return preds\n","\n","    def forward(self, x, y, x_lens, teacher_forcing_ratio=0.0):\n","        \"\"\"forward computation for training\n","\n","        `x` and `y` are padded tensors where:\n","        `x`: each row has valid tokens + EOS + possibly PADs\n","        `y`: except for row with longest valid length, has BOS + valid tokens + EOS + possibly PADs\n","        row with longest valid length has BOS + valid tokens, because `y` == `trees[:,:-1]`\n","        from the training loop in `train.py`\n","\n","        See Recitation Week 12 & 13 slides for details\n","\n","        Args:\n","          x: (batch_size, src_seq_len)\n","          y: (batch_size, tgt_seq_len)\n","          x_lens: (batch_size)\n","          teacher_forcing_ratio: float to determine whether to use teacher forcing\n","            at each decoding step\n","\n","        Returns:\n","          token-level logits, (batch_size, tgt_seq_len, tree_vocab_size)\n","        \"\"\"\n","        # encode step\n","        encoder_outputs, state = self.encoder(x, x_lens)\n","\n","        if teacher_forcing_ratio == 1.:\n","            assert self.model == C.VANILLA, \\\n","                f'full teacher forcing only supports Vanilla Seq2Seq, but your model is {self.model}'\n","\n","            # decode step with teacher forcing; let PyTorch iterate through `tgt_seq_len` dim internally\n","            outputs, _ = self.decoder(y, state)\n","        else:\n","            batch_size, tgt_seq_len = y.shape\n","\n","            # padding mask necessary for attentional decoders; not used by vanilla decoder\n","            # True if valid token, False otherwise (i.e. padding)\n","            padding_mask = x==self.sent_pad_idx\n","\n","            # decoding initial inputs as BOS, (batch_size, 1)\n","            yt = y[:, 0].unsqueeze(-1)\n","\n","            # the first two dimensions are swapped to make storing easier\n","            outputs = torch.zeros([tgt_seq_len, batch_size, self.tree_vocab_size], device=self.device)\n","\n","            # manual iteration through `tgt_seq_len` dimension\n","            for i in range(tgt_seq_len):\n","                # output: (batch_size, 1, tree_vocab_size)\n","                output, state = self.decoder(yt, state, encoder_outputs, padding_mask)\n","\n","                # save the model output: (1, batch_size, tree_vocab_size)\n","                outputs[i] = output.transpose(0, 1)\n","\n","                # decoding input: (batch_size, 1)\n","                if random.random() < teacher_forcing_ratio:\n","                    # without teacher forcing, use current prediction\n","                    yt = output.argmax(-1)\n","                else:\n","                    # with teacher forcing, fetch the next step's gold input\n","                    try:\n","                        yt = y[:,i+1].reshape([batch_size, 1])\n","                    except IndexError:\n","                        pass # last step, will terminate\n","\n","            # (batch_size, tgt_seq_len, tree_vocab_size)\n","            outputs = outputs.transpose(0, 1)\n","\n","        return outputs"],"id":"JyUgFxIOFUmP"},{"cell_type":"markdown","metadata":{"id":"hXL8x_KbFUmP"},"source":["## 3. Training"],"id":"hXL8x_KbFUmP"},{"cell_type":"markdown","metadata":{"id":"7e0xs3_SFUmP"},"source":["Here we do not import from `seq2seq.py`\n","* instead we use our models defined above"],"id":"7e0xs3_SFUmP"},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":974,"status":"ok","timestamp":1639771814105,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"CvA3jkyIFUmQ"},"outputs":[],"source":["import utils\n","from data_loader import PTB, init_data_loader, load_ptb_dataset\n","from inference import predict\n","import torch.optim as optim\n","import tqdm"],"id":"CvA3jkyIFUmQ"},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1639771814108,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"bXJk42UvFUmQ"},"outputs":[],"source":["# model path hyperparams\n","MODEL_DIR = './outputs/model'\n","GLOVE_DIR = None # Change this to your GloVe dir if you wish to use GloVe embedding"],"id":"bXJk42UvFUmQ"},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":146,"status":"ok","timestamp":1639771877488,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"SGr4IHrBFUmR"},"outputs":[],"source":["# model data hyperparams\n","GLOVE_NAME = C.GLOVE_6B\n","GLOVE_STRATEGY = C.KEEP_OVERLAP\n","WITH_TORCHTEXT = False\n","FINETUNE_GLOVE = False\n","SENT_THRESHOLD = 5\n","TREE_THRESHOLD = 5"],"id":"SGr4IHrBFUmR"},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1639771877636,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"mooGWGHEFUmR"},"outputs":[],"source":["# model hyperparams\n","EMBED_DIM = 300   # 100, 200, 300\n","RNN = C.LSTM      # C.RNN, C.GRU, C.LSTM\n","NUM_LAYERS = 2    # 1, 2, 3\n","HIDDEN_DIM = 256  # 64, 128, 256\n","DROPOUT = 0.2     # 0.2, 0.5, 0.7\n","\n","# model experiment hyperparams\n","EPOCHS = 10\n","EVAL_EVERY = 10\n","BATCH_SIZE = 68              # 68, 128, 200\n","LEARNING_RATE = 0.001        # 0.001, 0.005, 0.01\n","TEACHER_FORCING_RATIO = 0.75 # 0.5, 0.75\n","CHECKPOINT = None\n","SEED = 1334"],"id":"mooGWGHEFUmR"},{"cell_type":"markdown","metadata":{"id":"YoCyfUnaFUmR"},"source":["### A. Setup"],"id":"YoCyfUnaFUmR"},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1639771879874,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"WlRz-m3DFUmR","outputId":"0b5f6e91-2515-403d-a2ef-94c42bf5bcce"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(device(type='cuda'), './outputs/model/epoch_{}.pt')"]},"metadata":{},"execution_count":50}],"source":["os.path.abspath(MODEL_DIR)\n","os.makedirs(MODEL_DIR, exist_ok=True)\n","utils.set_seed(SEED)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# init model state dict filename\n","model_path_template = os.path.join(MODEL_DIR, C.MODEL_PT_TEMPLATE)\n","device, model_path_template"],"id":"WlRz-m3DFUmR"},{"cell_type":"markdown","metadata":{"id":"SMz42j6EFUmT"},"source":["### B. Load Vocab\n","initialize vocab itos and stoi from counter\n","###### Optionally load glove, which may modify `sent_vocab`"],"id":"SMz42j6EFUmT"},{"cell_type":"code","execution_count":60,"metadata":{"executionInfo":{"elapsed":151,"status":"ok","timestamp":1639772002645,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"1KJ6tC0-FUmT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"31877ca7-7eda-4d4e-ac0b-6804dbd7f5e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Vocab Info:\n","  Sent (11377) => <pad>, <unk>, <eos>, ,, the, ., !DIGITS, *, of, to, a, and, *T*, in, 's, that, for, *U*, $, ``, is, The, '', said, on, %, it, by, from, million, at, as, with, Mr., was, be, are, its, has, n't, an, will, have, !YEAR, he, or, company, year, which, would, about, --, says, they, were, this, market, more, billion, had, But, In, his, up, their, but, than, U.S., been, who, share, also, new, one, other, :, not, some, Corp., stock, I, years, New, shares, -RRB-, It, -LRB-, ;, could, all, Inc., last, two, out, &, trading, *ICH*, because, when, sales, ...\n","  Tree (195) => <pad>, <unk>, <bos>, <eos>, ), (NP, (VP, (NN, (IN, (NP-SBJ, (NNP, (S, (DT, (-NONE-, (JJ, (NNS, (PP, (,, (., (CD, (RB, (VBD, (VB, (CC, (SBAR, (TO, (VBZ, (VBN, (PRP, (VBG, (PP-LOC, (VBP, (PP-CLR, (ADVP, (MD, (QP, (WHNP, (POS, (PRP$, (PP-TMP, (ADJP, ($, (``, ('', (ADJP-PRD, (ADVP-TMP, (NP-PRD, (:, (PP-DIR, (NP-TMP, (WDT, (S-TPC, (JJR, (S-NOM, (SBAR-ADV, (NNPS, (RP, (PRT, (WHADVP, (NP-LGS, (ADVP-MNR, (PRN, (WP, (SBAR-TMP, (S-ADV, (WRB, (SINV, (NP-ADV, (JJS, (RBR, (NP-EXT, (PP-MNR, (-RRB-, (-LRB-, (S-PRP, (NX, (ADVP-LOC, (SBAR-PRP, (PP-PRD, (EX, (PP-PRP, (PP-LOC-CLR, (ADVP-CLR, (S-CLR, (NP-LOC, (ADVP-DIR, (PP-LOC-PRD, (FRAG, (SBAR-NOM, (ADVP-PRD, (RBS, (PP-DTV, (WHPP, (PDT, (SBAR-PRD, (SQ, (UCP, (CONJP, (NP-TTL, (S-NOM-SBJ, (NP-HLN, (FW, (NAC-LOC, (PP-EXT, (S-PRD, (SBARQ, (PP-PUT, (NP-CLR, (WP$, (ADVP-PRP, (X, (NAC, (ADVP-LOC-PRD, (#, (S-HLN, (INTJ, (SBAR-NOM-SBJ, (UH, (NP-TMP-CLR, (UCP-PRD, (S-PRP-CLR, (ADVP-EXT, (PP-TMP-CLR, (NX-TTL, (WHADJP, (SYM, (VP-TPC, (S-TTL, (S-CLF, (ADVP-LOC-CLR, (ADJP-CLR, (SBAR-SBJ, (SBAR-CLR, (RRC, (NP-MNR, (NP-TTL-SBJ, (SBAR-MNR, (SBAR-LOC, (PP-LOC-PRD-TPC, (S-MNR, (LST, (PP-TPC, (LS, (PP-BNF, (SBAR-NOM-PRD, (ADVP-LOC-PRD-TPC, (ADVP-PUT, (SBAR-PRP-PRD, (ADJP-PRD-TPC, (PP-LGS, (PP-TMP-PRD, (NAC-TMP, (NP-TPC, (NP-VOC, (ADJP-ADV, (PP-DIR-CLR, (UCP-LOC, (ADVP-PRD-TPC, (S-TMP, (S-SBJ, (UCP-TMP, (ADVP-TMP-CLR, (NP-TTL-PRD, (FRAG-TPC, (SBARQ-TPC, (NP-DIR, (PP-CLR-LOC, (S-NOM-PRD, (UCP-PRP, (SBAR-LOC-PRD, (SBAR-TPC, (PP-PRD-TPC, (NP-BNF, (PP-PRP-PRD, (ADVP-TMP-PRD, (PP-PRD-LOC, (PP-TTL, (FRAG-ADV, (ADJP-TPC, (UCP-CLR, (NP-TMP-HLN, (NP-LOC-PRD, (UCP-MNR, (PP-LOC-CLR-TPC, (NAC-TTL, (ADVP-TPC, (SBAR-NOM-LGS, (SQ-TPC, (X-ADV, (UCP-ADV, (NP-TMP-PRD, (PP-LOC-TPC, (NP-LOC-CLR, (FRAG-HLN, (NP-PRD-TPC\n"]}],"source":["sent_itos, sent_stoi = vocabs.init_vocab(vocab_counters[0], SENT_THRESHOLD, special_symbols=[C.PAD, C.UNK, C.EOS])\n","tree_itos, tree_stoi = vocabs.init_vocab(vocab_counters[1], TREE_THRESHOLD, special_symbols=[C.PAD, C.UNK, C.BOS, C.EOS])\n","\n","vocabs.display_vocabs(sent_itos, tree_itos)\n","\n","glove = None\n","if GLOVE_DIR is not None:\n","    glove, sent_itos, sent_stoi = vocabs.init_glove(\n","        glove_dir=GLOVE_DIR, name=GLOVE_NAME, embed_dim=EMBED_DIM, \n","        sent_itos=sent_itos, strategy=GLOVE_STRATEGY, with_torchtext=WITH_TORCHTEXT)"],"id":"1KJ6tC0-FUmT"},{"cell_type":"markdown","metadata":{"id":"E9-K92qvFUmU"},"source":["### C. Load PTB"],"id":"E9-K92qvFUmU"},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":159,"status":"ok","timestamp":1639772002983,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"OmV-INHHFUmU","outputId":"4bbb1a04-a2c4-4b66-b35c-9456fae6c2a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Dev PTB init\n","Sample vector from Dev\n","  Sent: Mrs. Hills said !DIGITS the U.S. wo n't accept any delays after Nov. !DIGITS because U.S. fish-processing firms enter into contracts *ICH* in the fall * to purchase the next season 's catch . <eos>\n","  Sent Vector: [983, 3529, 23, 6, 4, 67, 432, 39, 1534, 125, 2693, 102, 443, 6, 97, 67, 1, 414, 3002, 104, 663, 96, 13, 4, 676, 7, 9, 533, 4, 151, 1606, 14, 3081, 5, 2]\n","  Tree: <bos> (S (NP-SBJ (NNP ) (NNP ) ) (VP (VBD ) (SBAR (-NONE- ) (S (NP-SBJ (DT ) (NNP ) ) (VP (MD ) (RB ) (VP (VB ) (NP (DT ) (NNS ) ) (PP-TMP (IN ) (NP (NNP ) (CD ) ) ) (SBAR-PRP (IN ) (S (NP-SBJ (NNP ) (JJ ) (NNS ) ) (VP (VBP ) (PP-CLR (IN ) (NP (NNS ) (S (-NONE- ) ) ) ) (PP-TMP (IN ) (NP (DT ) (NN ) ) ) (S (NP-SBJ (-NONE- ) ) (VP (TO ) (VP (VB ) (NP (NP (DT ) (JJ ) (NN ) (POS ) ) (NN ) ) ) ) ) ) ) ) ) ) ) ) ) (. ) ) <eos>\n","  Tree Vector: [2, 11, 9, 10, 4, 10, 4, 4, 6, 21, 4, 24, 13, 4, 11, 9, 12, 4, 10, 4, 4, 6, 34, 4, 20, 4, 6, 22, 4, 5, 12, 4, 15, 4, 4, 39, 8, 4, 5, 10, 4, 19, 4, 4, 4, 77, 8, 4, 11, 9, 10, 4, 14, 4, 15, 4, 4, 6, 31, 4, 32, 8, 4, 5, 15, 4, 11, 13, 4, 4, 4, 4, 39, 8, 4, 5, 12, 4, 7, 4, 4, 4, 11, 9, 13, 4, 4, 6, 25, 4, 6, 22, 4, 5, 5, 12, 4, 14, 4, 7, 4, 37, 4, 4, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 3]\n"]}],"source":["dev_raw = load_ptb_dataset(DATA_DIR, C.DEV)\n","dev = PTB(C.DEV, dev_raw, sent_stoi, tree_stoi)"],"id":"OmV-INHHFUmU"},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2345,"status":"ok","timestamp":1639772005589,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"iFcknM_YFUmU","outputId":"b741f73e-2382-4fa8-fd97-bd61551f6c01"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Train PTB init\n","Sample vector from Train\n","  Sent: Morgan Stanley is expected * to price another junk bond deal , $ !DIGITS million *U* of senior subordinated debentures by Continental Cablevision Inc. , next Tuesday . <eos>\n","  Sent Vector: [915, 1415, 20, 174, 7, 9, 131, 265, 500, 408, 505, 3, 18, 6, 29, 17, 8, 462, 1510, 1392, 27, 1828, 10165, 90, 3, 151, 583, 5, 2]\n","  Tree: <bos> (S (NP-SBJ (NNP ) (NNP ) ) (VP (VBZ ) (VP (VBN ) (S (NP-SBJ (-NONE- ) ) (VP (TO ) (VP (VB ) (NP (NP (DT ) (NN ) (NN ) (NN ) ) (, ) (NP (NP (QP ($ ) (CD ) (CD ) ) (-NONE- ) ) (PP (IN ) (NP (JJ ) (JJ ) (NNS ) ) ) (PP (IN ) (NP (NNP ) (NNP ) (NNP ) ) ) ) (, ) ) (NP-TMP (JJ ) (NNP ) ) ) ) ) ) ) (. ) ) <eos>\n","  Tree Vector: [2, 11, 9, 10, 4, 10, 4, 4, 6, 26, 4, 6, 27, 4, 11, 9, 13, 4, 4, 6, 25, 4, 6, 22, 4, 5, 5, 12, 4, 7, 4, 7, 4, 7, 4, 4, 17, 4, 5, 5, 35, 41, 4, 19, 4, 19, 4, 4, 13, 4, 4, 16, 8, 4, 5, 14, 4, 14, 4, 15, 4, 4, 4, 16, 8, 4, 5, 10, 4, 10, 4, 10, 4, 4, 4, 4, 17, 4, 4, 49, 14, 4, 10, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 3]\n"]}],"source":["training_raw = load_ptb_dataset(DATA_DIR, C.TRAIN)\n","training = PTB(C.TRAIN, training_raw, sent_stoi, tree_stoi)"],"id":"iFcknM_YFUmU"},{"cell_type":"markdown","metadata":{"id":"jimdfqnSFUmU"},"source":["### D. Training Data Loader init"],"id":"jimdfqnSFUmU"},{"cell_type":"code","execution_count":63,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1639772005758,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"LTr3EUOwFUmU"},"outputs":[],"source":["train_dataloader = init_data_loader(training, sent_stoi, tree_stoi, BATCH_SIZE)"],"id":"LTr3EUOwFUmU"},{"cell_type":"markdown","metadata":{"id":"gi_Npbh1FUmU"},"source":["### E. Model init"],"id":"gi_Npbh1FUmU"},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"elapsed":179,"status":"ok","timestamp":1639773825885,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"Dj1QGamlFUmV","outputId":"0232ce21-704b-425c-c071-c045cd5a93a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Bahdanau Seq2Seq init\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'5,849,012'"]},"metadata":{},"execution_count":65}],"source":["model = Seq2Seq(\n","    model=C.BAHDANAU, sent_stoi=sent_stoi, tree_stoi=tree_stoi, embed_dim=EMBED_DIM, hidden_dim=HIDDEN_DIM, \n","    num_layers=NUM_LAYERS, dropout=DROPOUT, rnn_type=RNN, glove=glove, finetune_glove=FINETUNE_GLOVE, device=device)\n","\n","num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","f'{num_trainable_params:,}'"],"id":"Dj1QGamlFUmV"},{"cell_type":"markdown","metadata":{"id":"oLpPiC8FFUmV"},"source":["load from checkpoint and resume training if `CHECKPOINT` provided"],"id":"oLpPiC8FFUmV"},{"cell_type":"code","execution_count":66,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1639773826044,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"2y_aJRP5FUmV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1518b0db-fc59-44dd-dcf6-a2c5f74cd9a2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(11377, 300, padding_idx=0)\n","    (dropout): Dropout(p=0.2, inplace=False)\n","    (rnn): LSTM(300, 256, num_layers=2, batch_first=True)\n","  )\n","  (decoder): BahdanauAttentionDecoder(\n","    (embedding): Embedding(195, 300, padding_idx=0)\n","    (dropout): Dropout(p=0.2, inplace=False)\n","    (rnn): LSTM(300, 256, num_layers=2, batch_first=True)\n","    (dense): Linear(in_features=256, out_features=195, bias=True)\n","    (query_compute): Linear(in_features=256, out_features=256, bias=True)\n","    (key_compute): Linear(in_features=256, out_features=256, bias=True)\n","    (score_compute): Linear(in_features=256, out_features=1, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":66}],"source":["epoch = 0\n","if CHECKPOINT is not None:\n","    ckpt = torch.load(CHECKPOINT, map_location='cpu') # always load initially to RAM\n","    model.load_state_dict(ckpt['model'])\n","    epoch = ckpt['epoch']\n","    print(\"Resume training with Token-Level ACC {:.3f} | BLEU {:.2f} at epoch {}\".format(\n","      ckpt['acc'], ckpt['bleu'], epoch))\n","\n","# move all model parameters to `device`\n","model.to(device)"],"id":"2y_aJRP5FUmV"},{"cell_type":"markdown","metadata":{"id":"yGbcOI7iFUmV"},"source":["### F. Loss and Optimizer init"],"id":"yGbcOI7iFUmV"},{"cell_type":"code","execution_count":67,"metadata":{"executionInfo":{"elapsed":150,"status":"ok","timestamp":1639773827093,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"i8akbGV0FUmW"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss(ignore_index=tree_stoi[C.PAD])\n","optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"],"id":"i8akbGV0FUmW"},{"cell_type":"markdown","metadata":{"id":"1m-VU_8EFUmW"},"source":["### G. Training Loop"],"id":"1m-VU_8EFUmW"},{"cell_type":"markdown","metadata":{"id":"wdLLm6w8FUmW"},"source":["first, define eval function to be used inside training loop"],"id":"wdLLm6w8FUmW"},{"cell_type":"code","execution_count":74,"metadata":{"executionInfo":{"elapsed":37,"status":"ok","timestamp":1639783551917,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"},"user_tz":300},"id":"vLESGePvFUmW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"597e55ba-9378-4104-8876-1f026f772411"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9, 10)"]},"metadata":{},"execution_count":74}],"source":["def evaluate(model, dev, dev_raw, epoch, tree_itos, device):\n","    print(\"Begin Inference on Dev..\")\n","    preds, dev_acc = predict(model, dev, tree_itos, device)\n","\n","    # bleu\n","    bleu = utils.raw_corpus_bleu(preds, dev_raw[1])\n","    print('  Dev Token-level Accuracy: {:.3f} | BLEU: {:.2f}'.format(dev_acc, bleu))\n","\n","    # export model params and other misc info\n","    model_fpath = model_path_template.format(epoch+1)\n","    print(\"Exporting model params at\", model_fpath)\n","    torch.save({'model': model.state_dict(), 'epoch': epoch+1, 'acc': dev_acc, 'bleu': bleu},  model_fpath)\n","\n","    # export dev predictions\n","    dev_preds_path = os.path.join(MODEL_DIR, C.TREE_PRED_TEMPLATE.format('dev', f'_{epoch+1}'))\n","    print(\"Exporting dev predictions at\", dev_preds_path)\n","    utils.export_txt(preds, dev_preds_path)\n","\n","    # sample prediction display\n","    print(\"Sample Dev Prediction\")\n","    sample_idx = random.randint(0, len(dev)-1)\n","    print(\"  [SENT]\", dev_raw[0][sample_idx])\n","    sample_gold = dev_raw[1][sample_idx]\n","    print(f\"  [GOLD: {len(sample_gold.split())} toks]\", sample_gold)\n","    sample_pred = preds[sample_idx]\n","    print(f\"  [PRED: {len(sample_pred.split())} toks]\", sample_pred)\n","\n","# adjust target epoch value\n","target_epochs = 10\n","epoch, target_epochs"],"id":"vLESGePvFUmW"},{"cell_type":"code","execution_count":75,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x8U9zYmkFUmW","executionInfo":{"status":"ok","timestamp":1639783858289,"user_tz":300,"elapsed":306394,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"}},"outputId":"85e1d762-bf0f-41b2-b15b-04bae2e18cc0"},"outputs":[{"output_type":"stream","name":"stderr","text":["[Training 10/10]: 100%|██████████| 586/586 [03:45<00:00,  2.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":[" Training Loss: 399.27 Token-level Accuracy: 0.796\n","Begin Inference on Dev..\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1700/1700 [01:19<00:00, 21.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["  Dev Token-level Accuracy: 0.498 | BLEU: 67.14\n","Exporting model params at ./outputs/model/epoch_10.pt\n","Exporting dev predictions at ./outputs/model/dev_pred_10.txt\n","Sample Dev Prediction\n","  [SENT] Clients `` are all staying out '' of the market , one Merrill trader says !DIGITS *T* .\n","  [GOLD: 62 toks] (S (S-TPC (NP-SBJ (NP (NNS ) ) ) (`` ) (VP (VBP ) (DT ) (VP (VBG ) (PP-LOC (IN ) ('' ) (PP (IN ) (NP (DT ) (NN ) ) ) ) ) ) ) (, ) (NP-SBJ (CD ) (NNP ) (NN ) ) (VP (VBZ ) (SBAR (-NONE- ) (S (-NONE- ) ) ) ) (. ) )\n","  [PRED: 57 toks] (S (S-TPC (NP-SBJ ) ) (`` ) (VP (VBP ) (NP-PRD (DT ) ) ) ) (PRT (RP ) ) ('' ) (PP (IN ) (NP (DT ) (NN ) ) ) ) ) ) (NP-SBJ (NP-SBJ (NP-SBJ ) ) (NNP ) (NN ) ) (VP (VBZ ) (SBAR (-NONE- ) (S (-NONE- ) ) ) )\n"]}],"source":["for epoch in range(epoch, target_epochs):\n","    epoch_loss = 0\n","    num_correct = num_tokens = 0\n","\n","    for batch in tqdm.tqdm(train_dataloader, desc=f'[Training {epoch+1}/{target_epochs}]'):\n","        optimizer.zero_grad()\n","        sents, trees, sent_lens = utils.to_device(batch, device)\n","        # since last index of `trees` is always PAD or EOS, there is no need to predict a token with PAD or EOS as inputs when decoding; hence we omit it output logits: (batch_size, tgt_seq_len-1, vocab_size)\n","        outputs = model(sents, trees[:,:-1], sent_lens, teacher_forcing_ratio=TEACHER_FORCING_RATIO)\n","        # decoder output (gold target) that drops BOS at the beginning since BOS is never part of our predictions\n","        trees_target = trees[:,1:]\n","        # for the reason why `outputs` are transposed, see `Shape:` in https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n","        loss = criterion(outputs.transpose(1,2), trees_target)\n","        # token-level accuracy: (batch_size, tgt_seq_len-1) model predictions as ints: (batch_size, tgt_seq_len-1)\n","        preds = outputs.argmax(-1)\n","        trees_mask = trees_target == tree_stoi[C.PAD]\n","        num_correct += (preds==trees_target).masked_fill_(trees_mask, False).sum()\n","        num_tokens += (~trees_mask).sum() # includes <eos> which needs to be predicted correctly\n","        # optimizer step\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n","        optimizer.step()\n","        epoch_loss += loss.item()\n","\n","    acc = (num_correct.item() / num_tokens.item())\n","    print(' Training Loss: {:.2f} Token-level Accuracy: {:.3f}'.format(epoch_loss, acc))\n","    ### 7. eval on dev\n","    if (epoch+1) % EVAL_EVERY == 0:\n","        evaluate(model, dev, dev_raw, epoch, tree_itos, device)"],"id":"x8U9zYmkFUmW"},{"cell_type":"markdown","metadata":{"id":"-9lvW5WTFUmX"},"source":["## 4. Inference"],"id":"-9lvW5WTFUmX"},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uybl1mQjFUmX","executionInfo":{"status":"ok","timestamp":1639783858290,"user_tz":300,"elapsed":41,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"}},"outputId":"ef03ff9e-61c6-495c-d7d6-bf6ad352acdb"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test PTB init\n","Sample vector from Test\n","  Sent: This was an October massacre '' like those that *T* occurred in !YEAR and !YEAR . <eos>\n","  Sent Vector: [231, 34, 40, 688, 6183, 22, 187, 175, 15, 12, 3041, 13, 43, 11, 43, 5, 2]\n","  Tree: <bos> (S (NP-SBJ (DT ) ) (VP (VBD ) (NP-PRD (NP (DT ) (NNP ) (NN ) ) ('' ) (PP (IN ) (NP (NP (DT ) ) (SBAR (WHNP (WDT ) ) (S (NP-SBJ (-NONE- ) ) (VP (VBD ) (PP-TMP (IN ) (NP (CD ) (CC ) (CD ) ) ) ) ) ) ) ) ) ) (. ) ) <eos>\n","  Tree Vector: [2, 11, 9, 12, 4, 4, 6, 21, 4, 46, 5, 12, 4, 10, 4, 7, 4, 4, 43, 4, 16, 8, 4, 5, 5, 12, 4, 4, 24, 36, 50, 4, 4, 11, 9, 13, 4, 4, 6, 21, 4, 39, 8, 4, 5, 19, 4, 23, 4, 19, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 18, 4, 4, 3]\n"]}],"source":["# we already loaded `test_raw` when preparing data\n","test = PTB(C.TEST, test_raw, sent_stoi, tree_stoi)\n","INFERENCE_CKPT = None # if None, will use current `model` params"],"id":"Uybl1mQjFUmX"},{"cell_type":"code","execution_count":77,"metadata":{"id":"VYSJLXI4FUmX","executionInfo":{"status":"ok","timestamp":1639783858291,"user_tz":300,"elapsed":25,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"}}},"outputs":[],"source":["if INFERENCE_CKPT is not None:\n","    ckpt = torch.load(args.checkpoint, map_location='cpu')  # always load initially to RAM\n","    model.load_state_dict(ckpt['model'])\n","    print(\"Successfully loaded checkpoint from {}: Dev Token-Level ACC {:.3f} | BLEU {:.2f}\".format(\n","        args.checkpoint, ckpt['acc'], ckpt['bleu']))"],"id":"VYSJLXI4FUmX"},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xj0vUrVfFUmX","executionInfo":{"status":"ok","timestamp":1639783970996,"user_tz":300,"elapsed":112727,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"}},"outputId":"d16960c1-3c81-445a-e74e-778b572c8338"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2416/2416 [01:52<00:00, 21.45it/s]\n"]}],"source":["# run prediction step\n","preds, acc = predict(model, test, tree_itos, device)\n","# export predictions (this will overwrite existing prediction file)\n","preds_path = os.path.join(MODEL_DIR, C.TREE_PRED_TEMPLATE.format('test', ''))\n","utils.export_txt(preds, preds_path)"],"id":"Xj0vUrVfFUmX"},{"cell_type":"code","execution_count":79,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"BlCqvwC5FUmX","executionInfo":{"status":"ok","timestamp":1639783972166,"user_tz":300,"elapsed":1192,"user":{"displayName":"pop X","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07538672908640196703"}},"outputId":"eaaa89d1-0055-424d-ee08-9f2c62f3831f"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Test Token-level Accuracy: 0.491 | BLEU: 66.68'"]},"metadata":{},"execution_count":79}],"source":["# bleu\n","bleu = utils.raw_corpus_bleu(preds, test_raw[1])\n","\"Test Token-level Accuracy: {:.3f} | BLEU: {:.2f}\".format(acc, bleu)"],"id":"BlCqvwC5FUmX"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["Ss6hfbnRFUl8","xMTh6kmmFUmA","Z5CabmsWFUmE","WeRO4lAiFUmF","AZgmlG7xFUmH","v2trFqsfFUmH","ZenFNHLrFUmM","WVE8n3F2FUmN","9ojye3ETFUmO","hgRmuF3qFUmO","YoCyfUnaFUmR","SMz42j6EFUmT","E9-K92qvFUmU"],"machine_shape":"hm","name":"Wanyue_Xiao_PA4.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":5}